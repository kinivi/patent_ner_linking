{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA CENTER, DATA CENTER]\n",
      "617219114354912078 Hyponym 2 6 DATA CENTER such as DATA CENTER\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I used \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DATA CENTER\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " such as \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    DATA CENTER\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"spacy/model-best\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Add match ID \"HelloWorld\" with no callback and one pattern\n",
    "pattern = [{\"ENT_TYPE\": \"TECH\"},\n",
    "           {\"LOWER\": \"such\"},\n",
    "           {\"LOWER\": \"as\"},\n",
    "           {\"ENT_TYPE\": \"TECH\"}]\n",
    "matcher.add(\"Hyponym\", [pattern])\n",
    "\n",
    "doc = nlp(\"I used DATA CENTER such as DATA CENTER\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(span.ents)\n",
    "    print(match_id, string_id, start, end, span.text)\n",
    "\n",
    "colors = {\"TECH\": \"#F67DE3\"}\n",
    "options = {\"colors\": colors}\n",
    "spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relations(patents, patterns_lhypernym, patterns_rhypernym):\n",
    "  nlp = spacy.load(\"spacy/model-best\")\n",
    "  nlp.add_pipe(\"merge_entities\")\n",
    "  matcher = Matcher(nlp.vocab)\n",
    "\n",
    "  matcher.add(\"LHypernym\", patterns_lhypernym)\n",
    "  matcher.add(\"RHypernym\", patterns_rhypernym)\n",
    "\n",
    "  doc = nlp(patents)\n",
    "  matches = matcher(doc)\n",
    "  print(matches)\n",
    "\n",
    "  res = {\"Hypernyms\": []}\n",
    "\n",
    "  for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]  # The matched span\n",
    "\n",
    "    ent1 = span.ents[0]\n",
    "\n",
    "    for word in span.ents[1:]:\n",
    "      if string_id == \"LHypernym\":\n",
    "        res[\"Hypernyms\"].append((ent1, word))\n",
    "    \n",
    "      elif string_id == \"RHypernym\":\n",
    "        res[\"Hypernyms\"].append((word, ent1))\n",
    "      \n",
    "      else:\n",
    "        raise ValueError(f\"Unexpected match id: {string_id}\")\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11423821630223946117, 2, 6), (17216739248533801034, 7, 10)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Hypernyms': [(equipment rack, DATA CENTER), (DATA CENTER, thermal mass)]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns_rhypernym = [[{POS: \"NOUN\"},\n",
    "                        # Optional (0 or 1 matches) of comma\n",
    "                        {OP: '?', ORTH: \",\"},\n",
    "                        # matches if token.lower_ == 'such'\n",
    "                        {LOWER: \"such\"},\n",
    "                        {LOWER: \"as\"},\n",
    "                        {POS: \"NOUN\"}]]\n",
    "\n",
    "patterns_lhypernym = [[{\"ENT_TYPE\": \"TECH\"},\n",
    "                     {\"LOWER\": \"including\"},\n",
    "                     {\"ENT_TYPE\": \"TECH\"}]]\n",
    "\n",
    "compute_relations(\"I used DATA CENTER is an equipment rack. DATA CENTER including thermal mass\", patterns_lhypernym, patterns_rhypernym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9110b66360824545d7a7f0dbdfe5ab5407629db7e29fd63eb77836dd53cde7d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
