,word1,word2,relation,label,text
0,image processing,white balance,rhyper,-1,"The development processing unit 102 performs predetermined pixel interpolation or color conversion processing on the digital signal output from the imaging sensor unit 101, and generates digital video image data of, for example, R (red), G (green), B (blue), or Y (brightness), and UV (color difference). Further, the development processing unit 102 performs predetermined arithmetic processing using the digital video image data subjected to development processing, and performs image processing such as white balance, sharpness, contrast, and color conversion based on the obtained arithmetic processing result. Captured image data on which the image processing has been performed by the development processing unit 102 is sent, as input image data, to the moving object detection unit 103, the human body detection unit 104, the background image updating unit 106, and the like."
1,light source,light emitting diode,rhyper,-1,"In the shown example, the diffusing lighting device 30 is configured by an approximately semispherical reflector 30a of which an inner face is a diffusion reflecting surface, and a light source disposed in the reflector 30a. The light source may employ a known light source such as a light emitting diode (LED) or a halogen lamp."
2,wireless network,WI-FI network,rhyper,-1,"In particular embodiments, communication interface 810 includes hardware, software, or both providing one or more interfaces for communication (such as, for example, packet-based communication) between computer system 800 and one or more other computer systems 800 or one or more networks. As an example and not by way of limitation, communication interface 810 may include a network interface controller (NIC) or network adapter for communicating with an Ethernet or other wire-based network or a wireless NIC (WNIC) or wireless adapter for communicating with a wireless network, such as a WI-FI network. This disclosure contemplates any suitable network and any suitable communication interface 810 for it. As an example and not by way of limitation, computer system 800 may communicate with an ad hoc network, a personal area network (PAN), a local area network (LAN), a wide area network (WAN), a metropolitan area network (MAN), or one or more portions of the Internet or a combination of two or more of these. One or more portions of one or more of these networks may be wired or wireless. As an example, computer system 800 may communicate with a wireless PAN (WPAN) (such as, for example, a BLUETOOTH WPAN), a WI-FI network, a WI-MAX network, a cellular telephone network (such as, for example, a Global System for Mobile Communications (GSM) network), or other suitable wireless network or a combination of two or more of these. Computer system 800 may include any suitable communication interface 810 for any of these networks, where appropriate. Communication interface 810 may include one or more communication interfaces 810, where appropriate. Although this disclosure describes and illustrates a particular communication interface, this disclosure contemplates any suitable communication interface."
3,computer network,the Internet,rhyper,-1,"A plurality of components in the device 900 are coupled to the I/O interface 905, including: an input unit 906, such as a keyboard or a mouse; an output unit 907, such as various types of displays, or speakers; the storage unit 908, such as a disk or an optical disk; and a communication unit 909 such as a network card, a modem, or a wireless communication transceiver. The communication unit 909 allows the device 900 to exchange information/data with other devices over a computer network such as the Internet and/or various telecommunication networks."
4,a vehicle,passenger car,rhyper,-1,"In the present embodiment set forth below, the invention will be described using, as an example, a case where the authentication device 10 is installed in a vehicle such as a passenger car and an operation of the vehicle is provided as a service. In addition to the vehicle described in the present embodiment, the authentication device 10 according to the present embodiment can be installed at various places where a biometric authentication process is required for providing a service such as permitting entry or exit into or from a predetermined area such as a building and a room, and permitting withdrawal or deposit of money of an automated teller machine (ATM) and the like."
5,imaging technique,intravascular ultrasound imaging,rhyper,-1,"Systems and methods of the invention include image-processing techniques that provide automatic detection of objects, such as stents, within intraluminal images. Typically, the OCT intraluminal image is an intravascular image taken within a lumen of a blood vessel, but the detection methods described herein can be used to detect objects within other biological lumens, such as the intestine. Although the following description is directed towards detecting objects in OCT images, one skilled in the art would readily recognize that methods and systems of intention can be utilized to detect objects in any intraluminal images obtained from any other imaging technique, such as intravascular ultrasound imaging (IVUS) and combined OCT-IVUS."
6,electronic equipment,tablet computer,rhyper,-1,"Fig. 1 is a schematic flow chart showing a pressure determination method, according to an exemplary embodiment. The embodiment may be applied to a fingerprint recognition module, and the fingerprint recognition module may be configured in electronic equipment such as a mobile phone and a tablet computer. As shown in Fig. 1, the pressure determination method includes the following steps."
7,electronic equipment,mobile phone,rhyper,-1,"Fig. 1 is a schematic flow chart showing a pressure determination method, according to an exemplary embodiment. The embodiment may be applied to a fingerprint recognition module, and the fingerprint recognition module may be configured in electronic equipment such as a mobile phone and a tablet computer. As shown in Fig. 1, the pressure determination method includes the following steps."
8,recording medium,semiconductor memory,rhyper,-1,"Moreover, in the above embodiments, the structural components may be implemented as dedicated hardware or may be realized by executing a software program suited to such structural components. Alternatively, the structural components may be implemented by a program executor such as a CPU or a processor reading out and executing the software program recorded in a recording medium such as a hard disk or a semiconductor memory."
9,recording medium,hard disk,rhyper,-1,"Moreover, in the above embodiments, the structural components may be implemented as dedicated hardware or may be realized by executing a software program suited to such structural components. Alternatively, the structural components may be implemented by a program executor such as a CPU or a processor reading out and executing the software program recorded in a recording medium such as a hard disk or a semiconductor memory."
10,neural network,information processing model,hyper,1,"In this embodiment, the recognition model construction unit 104 uses a neural network in a learning model of the recognition model. For example, referring to Fig. 3, one example of a model of a neural network is illustrated. A neural network is an information processing model that uses the cranial nervous system as a model. The neural network is configured with plural node layers that include an input layer and an output layer. The node layer includes one or more nodes. Model information of the neural network indicates the number of node layers that configure the neural network, the number of nodes included in each of the node layers, and a type of the whole neural network or each of the node layers. For example, in a case where the neural network is configured with the input layer, one or more intermediate layers, and the output layer, with respect to information input to a node of the input layer, the neural network sequentially performs an output process from the input layer to the intermediate layer, a process in the intermediate layer, an output process from the intermediate layer to the next intermediate layer or to the output layer, a process in the output layer, and so forth and thereby outputs an output result that conforms to input information. Note that each node of one layer is connected with each node in the next layer, and the connection between the nodes is weighted. The weight to the connection between the nodes is added to information of the node of one layer, and the information is then output to the node of the next layer. The number of nodes of each of the input layer, the intermediate layers, and the output layer may variously be set."
11,3D applications,augmented reality,rhyper,-1,"The disclosed method simplifies the configuration of Points of interest for 3D applications, such as an augmented reality device. As e.g. only X,Y coordinates need to be associated with a 2D image."
12,electric vehicle,electric motor,rhyper,-1,"A vehicle as described in this specification may include all of an internal combustion engine vehicle including an engine as a power source, a hybrid vehicle including both an engine and an electric motor as a power source, and an electric vehicle including an electric motor as a power source."
13,electronic product,tablet personal computer,rhyper,-1,"Referring to FIG. 1, the electronic device 10 of the present embodiment at least includes a processor 110 and a storage unit 120, where the processor 110 is coupled to the storage unit 120. Moreover, in an embodiment, the electronic device 10 further includes an image capturing unit 130, and the processor 110 is coupled to the image capturing unit 130. The electronic device 10 of the present embodiment may be disposed on a mirror of a dressing table, and while the user looks at the mirror, the electronic device 10 may capture and analyze a face image of the user, and provide feedback information (for example, a face similarity evaluation result) by using a display (not shown) disposed behind the mirror. It should be noted that in other embodiments, the electronic device 10 may be an electronic product such as a smart phone, a tablet personal computer (PC), a desktop PC, etc., or a portable mirror box combined with a portable mirror."
14,electronic product,smart phone,rhyper,-1,"Referring to FIG. 1, the electronic device 10 of the present embodiment at least includes a processor 110 and a storage unit 120, where the processor 110 is coupled to the storage unit 120. Moreover, in an embodiment, the electronic device 10 further includes an image capturing unit 130, and the processor 110 is coupled to the image capturing unit 130. The electronic device 10 of the present embodiment may be disposed on a mirror of a dressing table, and while the user looks at the mirror, the electronic device 10 may capture and analyze a face image of the user, and provide feedback information (for example, a face similarity evaluation result) by using a display (not shown) disposed behind the mirror. It should be noted that in other embodiments, the electronic device 10 may be an electronic product such as a smart phone, a tablet personal computer (PC), a desktop PC, etc., or a portable mirror box combined with a portable mirror."
15,programming languages,object oriented programming language,rhyper,-1,"Computer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware instructions, state-setting data, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++ or the like, and conventional procedural programming languages, such as the ""C"" programming language or similar programming languages. The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider). In some embodiments, electronic circuitry including, for example, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic circuitry, in order to perform aspects of the present invention."
16,non-volatile memory,electrically erasable programmable read-only memory,rhyper,-1,"Step 204, DETERMINE FREE-SPACE, may include determining, with a controller 28 in communication with the perception-sensor 14, a free-space 30 defined as off of a roadway 22 traveled by the host-vehicle 12. The controller 28 is configured to control the host-vehicle 12, that may include vehicle-controls such as steering, brakes, and an accelerator. The controller 28 may include a processor (not shown) such as a microprocessor or other control circuitry such as analog and/or digital control circuitry including an application specific integrated circuit (ASIC) for processing data as should be evident to those in the art. The controller 28 may include a memory (not specifically shown), including non-volatile memory, such as electrically erasable programmable read-only memory (EEPROM) for storing one or more routines, thresholds, and captured data. The one or more routines may be executed by the processor to perform steps for determining if a detected instance of the object 16 and gradient 18 exists based on signals received by the controller 28 from the perception-sensor 14, as described herein."
17,color space,HSV color space,hyper,1,"5. The skin undertone determining method as claimed in claim 1, wherein  the first color space is a HSV color space, the first parameter value is a hue value in the HSV color space, and the second parameter value is a luminance value in the HSV color space, wherein the second color space is a RGB color space, and the third parameter value is a blue value in the RGB color space.."
18,color space,RGB color space,hyper,1,"5. The skin undertone determining method as claimed in claim 1, wherein  the first color space is a HSV color space, the first parameter value is a hue value in the HSV color space, and the second parameter value is a luminance value in the HSV color space, wherein the second color space is a RGB color space, and the third parameter value is a blue value in the RGB color space.."
19,communication network,cellular network,rhyper,-1,"The communication module 190 may support establishing a direct (e.g., wired) communication channel or a wireless communication channel between the electronic device 101 and the external electronic device (e.g., the electronic device 102, the electronic device 104, or the server 108) and performing communication via the established communication channel. The communication module 190 may include one or more communication processors that are operable independently from the processor 120 (e.g., the application processor (AP)) and supports a direct (e.g., wired) communication or a wireless communication. According to an embodiment, the communication module 190 may include a wireless communication module 192 (e.g., a cellular communication module, a short-range wireless communication module, or a global navigation satellite system (GNSS) communication module) or a wired communication module 194 (e.g., a local area network (LAN) communication module or a power line communication (PLC) module). A corresponding one of these communication modules may communicate with the external electronic device via the first network 198 (e.g., a short-range communication network, such as Bluetooth™, wireless-fidelity (Wi-Fi) direct, or infrared data association (IrDA)) or the second network 199 (e.g., a long-range communication network, such as a cellular network, the Internet, or a computer network (e.g., LAN or wide area network (WAN)). These various types of communication modules may be implemented as a single component (e.g., a single chip), or may be implemented as multi components (e.g., multi chips) separate from each other. The wireless communication module 192 may identify and authenticate the electronic device 101 in a communication network, such as the first network 198 or the second network 199, using subscriber information (e.g., international mobile subscriber identity (IMSI)) stored in the subscriber identification module 196."
20,communication network,computer network,rhyper,-1,"The communication module 190 may support establishing a direct (e.g., wired) communication channel or a wireless communication channel between the electronic device 101 and the external electronic device (e.g., the electronic device 102, the electronic device 104, or the server 108) and performing communication via the established communication channel. The communication module 190 may include one or more communication processors that are operable independently from the processor 120 (e.g., the application processor (AP)) and supports a direct (e.g., wired) communication or a wireless communication. According to an embodiment, the communication module 190 may include a wireless communication module 192 (e.g., a cellular communication module, a short-range wireless communication module, or a global navigation satellite system (GNSS) communication module) or a wired communication module 194 (e.g., a local area network (LAN) communication module or a power line communication (PLC) module). A corresponding one of these communication modules may communicate with the external electronic device via the first network 198 (e.g., a short-range communication network, such as Bluetooth™, wireless-fidelity (Wi-Fi) direct, or infrared data association (IrDA)) or the second network 199 (e.g., a long-range communication network, such as a cellular network, the Internet, or a computer network (e.g., LAN or wide area network (WAN)). These various types of communication modules may be implemented as a single component (e.g., a single chip), or may be implemented as multi components (e.g., multi chips) separate from each other. The wireless communication module 192 may identify and authenticate the electronic device 101 in a communication network, such as the first network 198 or the second network 199, using subscriber information (e.g., international mobile subscriber identity (IMSI)) stored in the subscriber identification module 196."
21,communication network,the Internet,rhyper,-1,"The communication module 190 may support establishing a direct (e.g., wired) communication channel or a wireless communication channel between the electronic device 101 and the external electronic device (e.g., the electronic device 102, the electronic device 104, or the server 108) and performing communication via the established communication channel. The communication module 190 may include one or more communication processors that are operable independently from the processor 120 (e.g., the application processor (AP)) and supports a direct (e.g., wired) communication or a wireless communication. According to an embodiment, the communication module 190 may include a wireless communication module 192 (e.g., a cellular communication module, a short-range wireless communication module, or a global navigation satellite system (GNSS) communication module) or a wired communication module 194 (e.g., a local area network (LAN) communication module or a power line communication (PLC) module). A corresponding one of these communication modules may communicate with the external electronic device via the first network 198 (e.g., a short-range communication network, such as Bluetooth™, wireless-fidelity (Wi-Fi) direct, or infrared data association (IrDA)) or the second network 199 (e.g., a long-range communication network, such as a cellular network, the Internet, or a computer network (e.g., LAN or wide area network (WAN)). These various types of communication modules may be implemented as a single component (e.g., a single chip), or may be implemented as multi components (e.g., multi chips) separate from each other. The wireless communication module 192 may identify and authenticate the electronic device 101 in a communication network, such as the first network 198 or the second network 199, using subscriber information (e.g., international mobile subscriber identity (IMSI)) stored in the subscriber identification module 196."
22,storage medium,non-volatile memory,rhyper,-1,"The external media 224 is a storage medium that stores image data and audio data, and it is removably connected to the image capture device 20. The I/O control portion 226 controls reading of the image data and the audio data that are stored in the external media 224, as well as writing of the image data and the audio data to the external media 224. Note that the external media 224 may be a storage medium such as a non-volatile memory, a magnetic disk, an optical disk, a magneto-optical (MO) disk, or the like. The non-volatile memory may be, for example, a flash memory, an SD card, a micro-SD card, a USB memory, an electrically erasable programmable read-only memory (EEPROM), or an erasable programmable ROM (EPROM). Further, the magnetic disk may be a hard disk, a disk-shaped magnetic disk, or the like. Furthermore, the optical disk may be a compact disc (CD), a digital versatile disc (DVD), a Blu-Ray disc (BD) (registered trademark), or the like."
23,storage medium,optical disk,rhyper,-1,"The external media 224 is a storage medium that stores image data and audio data, and it is removably connected to the image capture device 20. The I/O control portion 226 controls reading of the image data and the audio data that are stored in the external media 224, as well as writing of the image data and the audio data to the external media 224. Note that the external media 224 may be a storage medium such as a non-volatile memory, a magnetic disk, an optical disk, a magneto-optical (MO) disk, or the like. The non-volatile memory may be, for example, a flash memory, an SD card, a micro-SD card, a USB memory, an electrically erasable programmable read-only memory (EEPROM), or an erasable programmable ROM (EPROM). Further, the magnetic disk may be a hard disk, a disk-shaped magnetic disk, or the like. Furthermore, the optical disk may be a compact disc (CD), a digital versatile disc (DVD), a Blu-Ray disc (BD) (registered trademark), or the like."
24,storage medium,magnetic disk,rhyper,-1,"The external media 224 is a storage medium that stores image data and audio data, and it is removably connected to the image capture device 20. The I/O control portion 226 controls reading of the image data and the audio data that are stored in the external media 224, as well as writing of the image data and the audio data to the external media 224. Note that the external media 224 may be a storage medium such as a non-volatile memory, a magnetic disk, an optical disk, a magneto-optical (MO) disk, or the like. The non-volatile memory may be, for example, a flash memory, an SD card, a micro-SD card, a USB memory, an electrically erasable programmable read-only memory (EEPROM), or an erasable programmable ROM (EPROM). Further, the magnetic disk may be a hard disk, a disk-shaped magnetic disk, or the like. Furthermore, the optical disk may be a compact disc (CD), a digital versatile disc (DVD), a Blu-Ray disc (BD) (registered trademark), or the like."
25,display device,liquid crystal display,rhyper,-1,"Meanwhile, as a method for increasing the compression ratio of a moving image, it is also conceivable to reduce a noise signal in the moving image. However, the reduction of the noise signal in the moving image would be effective in the case of video conference using a projector or the like in a dark room, while the noise signal of the moving image is originally small in the case of video conference in a bright room, and thus, no large effect can be obtained. In recent years, a video conference often uses a backlight type display device such as a liquid crystal display to be performed in a bright room, making it difficult to improve the compression ratio of moving images even with the reduction of noise signals. According to the present embodiment, it is possible to further increase the compression ratio of a moving image as compared with such a technique of reducing noise signals."
26,electronic devices,mobile phones,rhyper,-1,"A fingerprint is unique, convenient and invariant over the life of an individual, and therefore has almost become a synonym for biometric recognition. Fingerprint recognition apparatuses are widely applied to various electronic devices such as mobile phones, tablet computers and the like. Currently, manufacturers have intended to mount a fingerprint recognition apparatus below a touch display screen, to implement under-display fingerprint recognition."
27,electronic devices,tablet computers,rhyper,-1,"A fingerprint is unique, convenient and invariant over the life of an individual, and therefore has almost become a synonym for biometric recognition. Fingerprint recognition apparatuses are widely applied to various electronic devices such as mobile phones, tablet computers and the like. Currently, manufacturers have intended to mount a fingerprint recognition apparatus below a touch display screen, to implement under-display fingerprint recognition."
28,input device,touch panel,rhyper,-1,"The input/output unit 140 is realized by an input device, such as a touch panel, mouse, keyboard, microphone, or camera (imaging device), and an output device, such as a display or speaker, included in the terminal device, for example. Note that the input/output unit 140 may also include only one of either an input device or an output device. For example, information received from the server 300 through the communication unit 120 is processed by the processing unit 130 and displayed on a display included in the input/output unit 140. As another example, user operating input acquired by a touch panel or the like included in the input/output unit 140 is processed by the processing unit 130 and transmitted to the server 300 through the communication unit 120."
29,control unit,control unit,hyper,1,"The switching circuit 27 includes a first analog switch (first switching element) 35 that connects and disconnects the voltage applying circuit 23 to and from the pre-head 10 and a second analog switch (second switching element) 36 that connects and disconnects the coupling capacitor 26 to and from the signal processing circuit 24. The switching circuit 27 also includes a switching element control unit configured to control on and off of the first analog switch 35 and the second analog switch 36. In the present embodiment, the switching control unit is the control unit 25. The control unit 25 switches on the first analog switch 35 and the second analog switch 35 based on signals from the detector 9."
30,personal information,telephone number,rhyper,-1,"FIG. 1 is a block diagram illustrating a schematic configuration of an image-linked data management system according to an embodiment of the present invention.FIG. 2 is an exemplary diagram illustrating a state in which a part of an area is enlarged through the image-linked data management system according to the embodiment of the present invention.FIG. 3 is an exemplary diagram illustrating a state in which personal information is output through the image-linked data management system according to the embodiment of the present invention.FIG. 4 is a diagram illustrating a state of dividing an original image through the image-linked data management system according to the embodiment of the present invention.FIG. 5 is a diagram illustrating a state in which an original image and personal information are simultaneously output through the image-linked data management system according to the embodiment of the present invention.FIG. 6 is a block diagram illustrating a configuration of an image data management server included in the image-linked data management system according to the embodiment of the present invention.FIG. 7 is a diagram illustrating a state in which bidding is performed for each image portion through the image-linked data management system according to the embodiment of the present invention.FIG. 8 is a diagram illustrating a state in which a community tool is formed on the basis of personal information such as a telephone number included in a specific original image through the image-linked data management system according to the embodiment of the present invention.FIG. 9 is a diagram illustrating a state of browsing an advertisement, and registering and transferring the personal information through the image-linked data management system according to the embodiment of the present invention."
31,operating system,mobile operating system,hyper,1,"The searching program obtains context information of the application program running in the foreground. In case that the operating system is a mobile operating system, by way of example, the operating system is provided with an active stack in which an activity located at a stack top is corresponding to a user interface of the application program running in the foreground; the searching program obtains an identifier of the application program running in the foreground and an identifier of the user interface from the activity located at the stack top. The identifier of the application program may be a package name to which the APP corresponds, while the identifier of the user interface may be a class name to which the user interface corresponds."
32,computer readable,magnetic disk,rhyper,-1,"The memory 152 stores therein information within the server 150. For example, the memory 152 may be a volatile memory unit or a non-volatile memory unit. The memory 152 may be another computer readable storage medium, such as a magnetic disk, an optical disk, or the like, for example."
33,computer readable,optical disk,rhyper,-1,"The memory 152 stores therein information within the server 150. For example, the memory 152 may be a volatile memory unit or a non-volatile memory unit. The memory 152 may be another computer readable storage medium, such as a magnetic disk, an optical disk, or the like, for example."
34,wireless communication,cellular communication,rhyper,-1,"On the basis of data of moving images captured by a high-precision image capturing device of the roadside apparatus, the controller 1011 or an information processor, not illustrated, connected to the roadside apparatus via the external I/F 1017 detects and identifies one or more objects present in and/or around an intersection, and the roadside apparatus distributes driving assistance information including information about the objects (for example, information about whether the objects are vehicles, pedestrians, or obstacles) to the onboard apparatus.The onboard apparatus mounted in a vehicle that is approaching an intersection transmits position information about the vehicle obtained by a satellite positioning system, such as a global navigation satellite system (GNSS), to the roadside apparatus via low-speed wireless communication, such as cellular communication, before the vehicle enters the intersection. In a case of receiving preliminary information from the onboard apparatus, the roadside apparatus expects the vehicle to enter the intersection and starts capturing images in and around the intersection at the timing when the vehicle enters the intersection.The onboard apparatus mounted on a vehicle that is approaching an intersection transmits in advance position information about the vehicle obtained by using retained map information, such as a dynamic map, to the roadside apparatus via low-speed wireless communication, such as cellular communication, before the vehicle enters the intersection. In a case of receiving preliminary information from the onboard apparatus, the roadside apparatus expects the vehicle to enter the intersection and starts capturing images in and around the intersection at the timing when the vehicle enters the intersection.In a case where the low-speed communicator of the roadside apparatus receives a radio wave of, for example, Bluetooth Low Energy (BLE) transmitted from a mobile device or the like carried by a person present in or around an intersection, the image capturers of the roadside apparatus start capturing images of the intersection and its surroundings, and the controller 1011 or an information processor, not illustrated, connected to the roadside apparatus via the external I/F 1017 detects and identifies the person present in or around the intersection. The millimeter-wave communicator of the roadside apparatus communicates driving assistance information including the result of detection and identification to the onboard apparatus in or around the intersection.In a case where the roadside apparatus determines that a warning needs to be issued in and around the intersection on the basis of at least one of the result of detection and identification of data from the image capturers, the preliminary information from the vehicle received by the low-speed communicator, and the radio wave from the mobile device carried by the person (for example, in a case where an object that is traveling in a direction at a speed significantly different from those in the usual traffic condition is identified), the roadside apparatus distributes driving assistance information in which the priority levels of the blind-spot areas are changed to the onboard apparatus in or around the intersection.In a case where a vehicle in which a rear detector not illustrated in the onboard apparatus 102 in Fig. 1 is mounted is located in or around an intersection and is detecting objects in the rear detection area, the UI 1026 preferentially displays rear-detection information. In a case where the objects move out of the rear detection area, the UI 1026 preferentially displays driving assistance information received from the roadside apparatus."
35,satellite positioning system,global navigation satellite system,rhyper,-1,"On the basis of data of moving images captured by a high-precision image capturing device of the roadside apparatus, the controller 1011 or an information processor, not illustrated, connected to the roadside apparatus via the external I/F 1017 detects and identifies one or more objects present in and/or around an intersection, and the roadside apparatus distributes driving assistance information including information about the objects (for example, information about whether the objects are vehicles, pedestrians, or obstacles) to the onboard apparatus.The onboard apparatus mounted in a vehicle that is approaching an intersection transmits position information about the vehicle obtained by a satellite positioning system, such as a global navigation satellite system (GNSS), to the roadside apparatus via low-speed wireless communication, such as cellular communication, before the vehicle enters the intersection. In a case of receiving preliminary information from the onboard apparatus, the roadside apparatus expects the vehicle to enter the intersection and starts capturing images in and around the intersection at the timing when the vehicle enters the intersection.The onboard apparatus mounted on a vehicle that is approaching an intersection transmits in advance position information about the vehicle obtained by using retained map information, such as a dynamic map, to the roadside apparatus via low-speed wireless communication, such as cellular communication, before the vehicle enters the intersection. In a case of receiving preliminary information from the onboard apparatus, the roadside apparatus expects the vehicle to enter the intersection and starts capturing images in and around the intersection at the timing when the vehicle enters the intersection.In a case where the low-speed communicator of the roadside apparatus receives a radio wave of, for example, Bluetooth Low Energy (BLE) transmitted from a mobile device or the like carried by a person present in or around an intersection, the image capturers of the roadside apparatus start capturing images of the intersection and its surroundings, and the controller 1011 or an information processor, not illustrated, connected to the roadside apparatus via the external I/F 1017 detects and identifies the person present in or around the intersection. The millimeter-wave communicator of the roadside apparatus communicates driving assistance information including the result of detection and identification to the onboard apparatus in or around the intersection.In a case where the roadside apparatus determines that a warning needs to be issued in and around the intersection on the basis of at least one of the result of detection and identification of data from the image capturers, the preliminary information from the vehicle received by the low-speed communicator, and the radio wave from the mobile device carried by the person (for example, in a case where an object that is traveling in a direction at a speed significantly different from those in the usual traffic condition is identified), the roadside apparatus distributes driving assistance information in which the priority levels of the blind-spot areas are changed to the onboard apparatus in or around the intersection.In a case where a vehicle in which a rear detector not illustrated in the onboard apparatus 102 in Fig. 1 is mounted is located in or around an intersection and is detecting objects in the rear detection area, the UI 1026 preferentially displays rear-detection information. In a case where the objects move out of the rear detection area, the UI 1026 preferentially displays driving assistance information received from the roadside apparatus."
36,state space model,Kalman filter,rhyper,-1,"In predicting influx number Rt+j after predetermined time (j), a number of customers in a particular section in store 200, attributes of customers (a gender, an age, and group information (a family, a couple, and the like)), a day of the week, a holiday, a season, and information about events around store 200 may be used as variable C used for prediction. A prediction system is not limited to the multiple regression prediction, and a time series prediction model such as an ARIMA model and an ARCH model may be used. Additionally, prediction may be performed using a state space model such as a Kalman filter or a Particle filter. Deep learning may also be used."
37,state space model,Particle filter,rhyper,-1,"In predicting influx number Rt+j after predetermined time (j), a number of customers in a particular section in store 200, attributes of customers (a gender, an age, and group information (a family, a couple, and the like)), a day of the week, a holiday, a season, and information about events around store 200 may be used as variable C used for prediction. A prediction system is not limited to the multiple regression prediction, and a time series prediction model such as an ARIMA model and an ARCH model may be used. Additionally, prediction may be performed using a state space model such as a Kalman filter or a Particle filter. Deep learning may also be used."
38,computer system,central processing unit,rhyper,-1,"The moving body system 1 includes a control unit 15. The control unit 15 is a computer system including a central processing unit (CPU), a storage device (a random access memory (RAM), a read only memory (ROM), a solid state drive (SSD), a hard disk drive (HDD), or the like) and various interfaces (for example, an A/D converter, a D/A converter, and the like)."
39,communications device,mobile telephone,rhyper,-1,"Embodiments of electronic devices, user interfaces for such devices, and associated processes for using such devices are described. In some embodiments, the device is a portable communications device, such as a mobile telephone, that also contains other functions, such as PDA and/or music player functions. Exemplary embodiments of portable multifunction devices include, without limitation, the iPhone®, iPod Touch®, and iPad® devices from Apple Inc. of Cupertino, California. Other portable electronic devices, such as laptops or tablet computers with touch-sensitive surfaces (e.g., touch screen displays and/or touchpads), are, optionally, used. It should also be understood that, in some embodiments, the device is not a portable communications device, but is a desktop computer with a touch-sensitive surface (e.g., a touch screen display and/or a touchpad)."
40,wide area network,enterprise network,rhyper,-1,"Such computers may be interconnected by one or more networks in any suitable form, including as a local area network or a wide area network, such as an enterprise network or the Internet. Such networks may be based on any suitable technology and may operate according to any suitable protocol and may include wireless networks, wired networks or fiber optic networks."
41,wide area network,the Internet,rhyper,-1,"Such computers may be interconnected by one or more networks in any suitable form, including as a local area network or a wide area network, such as an enterprise network or the Internet. Such networks may be based on any suitable technology and may operate according to any suitable protocol and may include wireless networks, wired networks or fiber optic networks."
42,vertical axis,scan line,hyper,1,"Fig. 12 illustrates an exemplary timing chart on the exposure/reading processing per region in the pixel region 800. As described above, the exposure/reading processing in the center region 801 and the peripheral regions 802 and 803 is performed in parallel. The horizontal axis is a time axis and the vertical axis is a scan line (row number) in the Figure. Here, the imaging device assumes an imaging device configured to perform the reading operation per row such as CMOS image sensor."
