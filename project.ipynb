{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "604a1483-2ecb-444d-8ffc-802648c34911",
   "metadata": {},
   "source": [
    "# Information Retrieval project 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec106c",
   "metadata": {},
   "source": [
    "## üßë‚Äçüéì Names\n",
    "+ Mashra Marwan\n",
    "+ Kiselov Nikita\n",
    "+ Serr√© Ga√´tan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1072fe45",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48f9c4b-cdb4-4eab-aae2-3f4c6f81793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher, Matcher\n",
    "from spacy.util import filter_spans\n",
    "from spacy import displacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.tokens import Span\n",
    "from collections import Counter\n",
    "from nltk.tokenize import MWETokenizer\n",
    "from nltk.util import Trie\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "tqdm.pandas()\n",
    "spacy.__version__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f564de",
   "metadata": {},
   "source": [
    "Our first goal here is to create a model capable of recognizing the term in our patents. For that, we will be using a Named Entity Recognition model given by `spacy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632e188",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb325a64-2f8b-4f2f-aae8-be361087e045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you've already unzipped the file\n",
    "patent_data=open('G06K.txt').read().strip()\n",
    "\n",
    "# split into patents texts | 1 entry = 1 patent\n",
    "patent_texts = patent_data.split('\\n\\n')\n",
    "\n",
    "# split each patent into lines\n",
    "patent_lines = patent_data.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81139208",
   "metadata": {},
   "source": [
    "## üëÄ Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f35b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antonio superchi', 'antonio tarver', 'antonio torres jurado', 'antonio valdes', 'antonio valdes y fernandez bazan', 'antonio valdez', 'antonio vald√©s y baz√°n', 'antonio vald√©s y fern√°ndez baz√°n', 'antonio valente', 'antonio vitali', 'antonio vivaldi', 'antonio xavier machado e cerveira']\n",
      "743274 mwes\n"
     ]
    }
   ],
   "source": [
    "# here are the potential terms\n",
    "mwes = open('manyterms.lower.txt').read().lower().strip().split('\\n')\n",
    "print(mwes[44444:44456])\n",
    "print(len(mwes),'mwes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8543e66",
   "metadata": {},
   "source": [
    "### We extract the terms from our patents using manyterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db03d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaetanserre/miniconda3/envs/NLP/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1322: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "/Users/gaetanserre/miniconda3/envs/NLP/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>electronic device</th>\n",
       "      <td>16280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image processing</th>\n",
       "      <td>12224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control unit</th>\n",
       "      <td>9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile terminal</th>\n",
       "      <td>9165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information processing</th>\n",
       "      <td>7732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural network</th>\n",
       "      <td>6734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user interface</th>\n",
       "      <td>6177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer readable</th>\n",
       "      <td>6103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fingerprint sensor</th>\n",
       "      <td>5980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display device</th>\n",
       "      <td>5666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light source</th>\n",
       "      <td>5014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>block diagram</th>\n",
       "      <td>4597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image sensor</th>\n",
       "      <td>4421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computing device</th>\n",
       "      <td>4407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road surface</th>\n",
       "      <td>4398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storage medium</th>\n",
       "      <td>4377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fingerprint recognition</th>\n",
       "      <td>3848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning</th>\n",
       "      <td>3778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>control device</th>\n",
       "      <td>3714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point cloud</th>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threshold value</th>\n",
       "      <td>3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data processing</th>\n",
       "      <td>3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real time</th>\n",
       "      <td>3353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wireless communication</th>\n",
       "      <td>3338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer program</th>\n",
       "      <td>3206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "electronic device        16280\n",
       "image processing         12224\n",
       "control unit              9263\n",
       "mobile terminal           9165\n",
       "information processing    7732\n",
       "neural network            6734\n",
       "user interface            6177\n",
       "computer readable         6103\n",
       "fingerprint sensor        5980\n",
       "display device            5666\n",
       "light source              5014\n",
       "block diagram             4597\n",
       "image sensor              4421\n",
       "computing device          4407\n",
       "road surface              4398\n",
       "storage medium            4377\n",
       "fingerprint recognition   3848\n",
       "machine learning          3778\n",
       "control device            3714\n",
       "point cloud               3713\n",
       "threshold value           3705\n",
       "data processing           3366\n",
       "real time                 3353\n",
       "wireless communication    3338\n",
       "computer program          3206"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here lowercase=False option is used to keep the original case of the terms, since we possibly could have term abbreviations. Like API, CAT, etc.\n",
    "cvectorizer = CountVectorizer(ngram_range=(1, 4), stop_words=\"english\", vocabulary=mwes, lowercase=True)\n",
    "X=cvectorizer.fit_transform(patent_texts)\n",
    "\n",
    "# Show top-25 most frequent terms\n",
    "termdf_cv = pd.DataFrame(np.sum(X, axis=0), columns=cvectorizer.get_feature_names()).T.sort_values(by = 0, ascending = False)\n",
    "termdf_cv.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865bc096",
   "metadata": {},
   "source": [
    "## ü™Ñ SpaCy NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040a3849",
   "metadata": {},
   "source": [
    "Let's start from understanding. Here is an example of showing part of text on one patent with default NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "094a3dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"> PC \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    503\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " are \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " example of the communication device and may also be other various devices such as, for example, a smart phone, a camera, a digital television set, various digital consumer electronics, and a wearable device.</br>It should be noted that the setting device is \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " type of the communication device, but according to the present embodiment, a communication device provided with a function for obtaining a public key of another communication device by a specific obtaining method that does not use the wireless \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    LAN\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " will be referred to as a setting device to be distinguished from the communication device that is not provided with such a function. On the other hand, a communication device that is not provided with such a function will be simply referred to as a communication device. As described above, according to the present embodiment, the smart phone \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    501\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " is \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " example of the setting device, and the printer \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    502\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " and the laptop PC \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    503\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " are \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " example of the communication device. In addition, according to the present embodiment, the public key obtaining method using the QR code is an example of the above-described particular obtaining method. In this case, a function for reading the QR code is an example of a function for obtaining the public key of the other communication device by the particular obtaining method. Other examples of the particular obtaining method may also be \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NFC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bluetooth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (registered trademark), or a wireless communication other than the wireless \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    LAN\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". In this case, an example of the function for obtaining the public key of the other communication device by the particular obtaining method includes an \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NFC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " reader/writer function.</br>According to the present embodiment, the smart phone \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    501\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " serving as the setting device has the configuration of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fig\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fig\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " described before. In addition, the printer \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    502\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " and the laptop PC \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    503\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " serving as the communication device have the configuration of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fig\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Fig\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    4\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " described before.</br>Fig. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    6\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " is a flow chart illust</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(patent_texts[0][18000:20000]) # \n",
    "displacy.render(doc, style=\"ent\", jupyter = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc4869",
   "metadata": {},
   "source": [
    "We want to create a such model capable of recognizing the terms that are in the context of our patents. For that, we need to create a dataset and we will be using `manyterms` as a terms database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a11a5c7",
   "metadata": {},
   "source": [
    "### Create DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96e5ed8",
   "metadata": {},
   "source": [
    "We need to create propper dataset that is compatible with SpaCy 3.0 to train a NER model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ee5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "patterns = [nlp.make_doc(text) for text in termdf_cv.index]\n",
    "matcher.add(\"Tech\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03304083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines, test_lines = train_test_split(patent_lines, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e8ccf",
   "metadata": {},
   "source": [
    "We are using PharsesMatcher to find entities similar to one from mayterms.txt  \n",
    "Then Span is labeled and saved into the binary `.spacy` format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466965e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(text, n_lines, filename, offset=0):\n",
    "  LABEL = \"TECH\"\n",
    "  doc_bin = DocBin() # create a DocBin object\n",
    "\n",
    "  for training_example  in tqdm(text[offset:offset+n_lines]):\n",
    "      doc = nlp.make_doc(training_example) \n",
    "      ents = []\n",
    "      \n",
    "      for match_id, start, end in matcher(doc):\n",
    "          span = Span(doc, start, end, label=LABEL)\n",
    "          if span is None:\n",
    "              print(\"Skipping entity\")\n",
    "          else:\n",
    "              ents.append(span)\n",
    "\n",
    "      filtered_ents = filter_spans(ents)\n",
    "      doc.ents = filtered_ents \n",
    "      doc_bin.add(doc)\n",
    "  doc_bin.to_disk(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61472477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed40583115c64e738e6de2441d1f4368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4188f55ae26e42248df6ee7b10f5ba4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_dataset(train_lines, 40_000, \"training_data.spacy\")\n",
    "create_dataset(test_lines, 12_000, \"valid_data.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382425f8",
   "metadata": {},
   "source": [
    "Now that our datasets are created, we can train a spacy NER model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb93f6",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5578e31",
   "metadata": {},
   "source": [
    "Donwnload __base_config.cfg__ for your system at https://spacy.io/usage/training#quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cd8a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m‚úî Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m‚úî Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# Run to generate full training config\n",
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba2d3df",
   "metadata": {},
   "source": [
    "Run the training. The best and last model will be stored into __./spacy_output__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae2949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy train config.cfg --output ./spacy_output --paths.train ./training_data.spacy --paths.dev ./valid_data.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df35c0b",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3374131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaetanserre/miniconda3/envs/NLP/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wi-Fi Direct\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    registered trademark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ", which will be hereinafter referred to as WFD)            corresponding to a technology for directly performing a communication based on a            \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    wireless LAN\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " between communication devices without intermediation of an access            point (hereinafter referred to as AP) is standardized in \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wi-Fi Alliance\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " serving            as a \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    wireless LAN\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " industry group.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"spacy_output/model-best\")\n",
    "\n",
    "doc = nlp(\"Wi-Fi Direct (registered trademark, which will be hereinafter referred to as WFD) \\\n",
    "           corresponding to a technology for directly performing a communication based on a \\\n",
    "           wireless LAN between communication devices without intermediation of an access \\\n",
    "           point (hereinafter referred to as AP) is standardized in Wi-Fi Alliance serving \\\n",
    "           as a wireless LAN industry group.\")\n",
    "\n",
    "colors = {\"TECH\": \"#F67DE3\"}\n",
    "options = {\"colors\": colors} \n",
    "\n",
    "spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c4897",
   "metadata": {},
   "source": [
    "In our patents, a lot of terms are abbreviated.\n",
    "For example, `WI-FI Direct` is mentioned as `WFD`, or `P2P Group Owner` as `GO`.\n",
    "\n",
    "Our original model does not recognize these abbreviations and therefore a huge part of the terms are ignored.\n",
    "So we will fine-tune our model using prodigy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91010601",
   "metadata": {},
   "source": [
    "## ü¶Ñ Prodigy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc0db74",
   "metadata": {},
   "source": [
    "We create a train dataset for fine-tuning our ner model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !prodigy ner.correct fine_tune_g06k2 spacy_output/model-best G06K.txt --loader txt --label TECH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d85e743",
   "metadata": {},
   "source": [
    "<img src=img/annotations.png style=\"width: 40%; height:40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52543ec3",
   "metadata": {},
   "source": [
    "Now let's fine-tune our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62103584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !prodigy train ./prodigy_output/ --ner fine_tune_g06k --base-model spacy_output/model-best --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412acd95",
   "metadata": {},
   "source": [
    "Now our refined model should recognize better the abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5174e6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">According to the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WFD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ", the communication is performed when one of the            \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    communication devices\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " that directly perform the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    wireless LAN\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " communication            operates as the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ". According to the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WFD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ", a role of the device that operates            as the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " will be referred to as \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    P2P Group Owner\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " (hereinafter, referred to as \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GO\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ").            On the other hand, a role of the device that participates in a network generated by            the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GO\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " will be referred to as \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    P2P Client\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " (hereinafter, referred to as \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CL\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ").            According to the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WFD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ", a \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    communication parameter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " necessary for participating in            the network generated by the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GO\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " is shared between the devices by transmitting the            \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    communication parameter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " from the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    GO\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " to the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CL\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ", and thereafter, the wireless            communication according to the \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    WFD\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       " is executed on the basis of the shared \n",
       "<mark class=\"entity\" style=\"background: #F67DE3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    communication parameter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TECH</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = spacy.load(\"prodigy_output/model-best\")\n",
    "\n",
    "doc = nlp(\"According to the WFD, the communication is performed when one of the \\\n",
    "           communication devices that directly perform the wireless LAN communication \\\n",
    "           operates as the AP. According to the WFD, a role of the device that operates \\\n",
    "           as the AP will be referred to as P2P Group Owner (hereinafter, referred to as GO). \\\n",
    "           On the other hand, a role of the device that participates in a network generated by \\\n",
    "           the GO will be referred to as P2P Client (hereinafter, referred to as CL). \\\n",
    "           According to the WFD, a communication parameter necessary for participating in \\\n",
    "           the network generated by the GO is shared between the devices by transmitting the \\\n",
    "           communication parameter from the GO to the CL, and thereafter, the wireless \\\n",
    "           communication according to the WFD is executed on the basis of the shared communication parameter.\")\n",
    "\n",
    "colors = {\"TECH\": \"#F67DE3\"}\n",
    "options = {\"colors\": colors} \n",
    "\n",
    "spacy.displacy.render(doc, style=\"ent\", options=options, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9455da",
   "metadata": {},
   "source": [
    "This fine tuned model is more accurate than the first one. We will use it in our Hearst patterns recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa5ef8",
   "metadata": {},
   "source": [
    "## üß¨ Hearst Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef11613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hearst_Patterns:\n",
    "    \"\"\" Extracts hearst patterns from a corpus\n",
    "    \"\"\"\n",
    "    def __init__(self, patterns_file=\"patterns.json\", model_path=\"spacy/model-new\", text_path=\"G06K.txt\"):\n",
    "        \"\"\" creates an instance of the class Hearst_Patterns\n",
    "\n",
    "        Args:\n",
    "            patterns_file (path, optional): the json file containing the patterns. Defaults to \"patterns.json\".\n",
    "            model_path (path, optional): the folder containing the NER model to use. Defaults to \"spacy/model-new\".\n",
    "            text_path (path, optional): the file containing the corpus analyse and extract patterns. Defaults to \"G06K.txt\".\n",
    "        \"\"\"\n",
    "\n",
    "        # read the text file\n",
    "        g06k = open(text_path).read().strip()\n",
    "        self.patent_lines = g06k.split('\\n')\n",
    "        \n",
    "        # load the models\n",
    "        self.nlp = spacy.load(model_path)\n",
    "        self.en_nlp = spacy.load(\"en_core_web_lg\")\n",
    "        self.nlp.add_pipe(\"merge_entities\")\n",
    "        self.en_nlp.add_pipe('merge_noun_chunks')\n",
    "\n",
    "        self.matcher = Matcher(self.nlp.vocab)\n",
    "        self.patterns = self.load_patterns_from_json(patterns_file)\n",
    "        for name, pattern in self.patterns:\n",
    "            self.matcher.add(name, pattern)\n",
    "\n",
    "        # this list is used in the method get_matches\n",
    "        self.continue_words = [',','and','or',';','also','as well']\n",
    "\n",
    "\n",
    "    def load_patterns_from_json(self, patterns_file):\n",
    "        \"\"\" read the json file and return the list of\n",
    "\n",
    "        Args:\n",
    "            patterns_file (path): the json file containing the patterns\n",
    "\n",
    "        Returns:\n",
    "            List: a list of the hearst patterns found in the json file  \n",
    "        \"\"\"\n",
    "        f = open(patterns_file)\n",
    "        data = json.load(f)\n",
    "        patterns = []\n",
    "        for name, pattern in data.items():\n",
    "            patterns.append((name, pattern))\n",
    "\n",
    "        return patterns\n",
    "\n",
    "\n",
    "    def extract_patterns(self, size=10, save_folder=\".\", start=0):\n",
    "        \"\"\" look for matches in a corpus (text file)\n",
    "\n",
    "        Args:\n",
    "            size (int, optional): the minimum number of matches to be found. Defaults to 10.\n",
    "            save_folder (path, optional): the folder in which save the resulted csv file. Defaults to \".\".\n",
    "            start (int, optional): the first line in which we start to look for matches (useful to continue where you stopped). Defaults to 0.\n",
    "        \"\"\"\n",
    "        extraced_patterns = []\n",
    "\n",
    "        # chose a start\n",
    "        line = start\n",
    "        count = 0\n",
    "\n",
    "        # for the output \n",
    "        print(f'{count} pattern extracted...', end='\\r')\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        while count<size:\n",
    "            while True: # we read line by line until finding a match, to keep track of the count \n",
    "                try: # it bugs very rarely, don't know why XD  \n",
    "\n",
    "                    # look for a match\n",
    "                    patterns = self.get_matches(self.patent_lines[line])\n",
    "                    if patterns:\n",
    "                        extraced_patterns += patterns\n",
    "                        break\n",
    "                    print(f'{count} patterns extracted...{line}', end='\\r')\n",
    "                    sys.stdout.flush()\n",
    "                except:\n",
    "                    print(\"An error has occurred\")\n",
    "                \n",
    "                line += 1\n",
    "            count = len(extraced_patterns)\n",
    "            print(f'{count} patterns extracted...{line}', end='\\r')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "\n",
    "        print(f'({count}) patterns extracted from lines ({start}-{line}))')\n",
    "        save_file = f\"{save_folder}/hearst_patterns.{len(extraced_patterns)}.csv\"\n",
    "        print(f'Patterns saved to {save_file}')\n",
    "        df = pd.DataFrame(extraced_patterns, columns =['word1', 'word2', 'relation', 'label', 'text'])\n",
    "        df.to_csv(save_file)\n",
    "\n",
    "    def get_matches(self, text):\n",
    "        label = {\n",
    "            'rhyper':-1,\n",
    "            'hyper':1,\n",
    "        }\n",
    "        doc = self.nlp('. '+text) # because patterns like < !(bla bla) X > don't work when X is in the beginning of the sentence \n",
    "        \n",
    "        matches = self.matcher(doc)\n",
    "        relations = []\n",
    "        for match_id, start, end in matches:\n",
    "\n",
    "            # get all entities indices in the doc\n",
    "            ent_indices = [i for i in range(start,end) if doc[i].text in [ent.text for ent in doc[start:end].ents]]\n",
    "            if not ent_indices: # no entity found\n",
    "                return []\n",
    "\n",
    "            # extract X...Y from a match ..X...Y.., so now we know that the first and the last token are the entities\n",
    "            span = doc[min(ent_indices):max(ent_indices)+1]\n",
    "\n",
    "            match_info = self.nlp.vocab.strings[match_id]  # Get string representation\n",
    "            match_name = match_info.split('-')[0]   # hyper or rhyper\n",
    "            match_type = match_info.split('-')[1]   # single or multi\n",
    "\n",
    "            np_0 = span[0]  # left term\n",
    "            np_1 = span[-1] # right term (or first right term if multiple)\n",
    "\n",
    "            # all the right terms (ex. for Y...X1, X2, ...Xn) X1...Xn are the right terms\n",
    "            right_terms = [np_1.text]\n",
    "            if match_type==\"multi\": # look for other terms (X2,X3..etc)\n",
    "\n",
    "                # we use the en_core_web_lg model to get the noun chunks\n",
    "                doc_en = self.en_nlp(doc[end:].text)\n",
    "                for d in doc_en:\n",
    "                    # look for entities inside the noun chunk\n",
    "                    matching_ents = [ent.text for ent in doc.ents if ent.text in d.text]\n",
    "                    if matching_ents:\n",
    "                        right_terms.append(matching_ents[0])\n",
    "                    elif d.text not in self.continue_words:  # stop when seeing a word that's not in the list\n",
    "                        break\n",
    "\n",
    "            for term in right_terms:\n",
    "                relations.append((np_0.text, term, match_name, label[match_name], text))\n",
    "\n",
    "        relations = set(relations)\n",
    "        return list(relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4000f",
   "metadata": {},
   "source": [
    "### ‚õ∑Ô∏è start the extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fe5b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-04-21 02:13:14 +02:00)\n"
     ]
    }
   ],
   "source": [
    "hp = Hearst_Patterns(patterns_file=\"patterns.json\", model_path=\"../spacy/model-new\", text_path=\"../G06K.txt\")\n",
    "hp.extract_patterns(size=50, start=5896, save_folder=\"hearst_patterns/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa5f04",
   "metadata": {},
   "source": [
    "### ‚ú® Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f035a2",
   "metadata": {},
   "source": [
    "in the first <b>26331</b>, we found <b>245</b> different matches, <b>155</b> unique relation. Here are some of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76367a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hypernym</th>\n",
       "      <th>Hyponym</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>home appliance</td>\n",
       "      <td>mobile robot</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer network</td>\n",
       "      <td>the Internet</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>Deep learning</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electronic device</td>\n",
       "      <td>electronic component</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>storage device</td>\n",
       "      <td>hard disk</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>communication network</td>\n",
       "      <td>the Internet</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>point light source</td>\n",
       "      <td>light source</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the environment</td>\n",
       "      <td>foot traffic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>storage media</td>\n",
       "      <td>hard drives</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>laser projector</td>\n",
       "      <td>display device</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Hypernym               Hyponym  Frequency\n",
       "0           home appliance          mobile robot         15\n",
       "1         computer network          the Internet         10\n",
       "2  artificial intelligence         Deep learning          6\n",
       "3        electronic device  electronic component          4\n",
       "4           storage device             hard disk          4\n",
       "5    communication network          the Internet          4\n",
       "6       point light source          light source          4\n",
       "7          the environment          foot traffic          3\n",
       "8            storage media           hard drives          3\n",
       "9          laser projector        display device          3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.read_csv(\"hearst_patterns/hearst_patterns.155.csv\", index_col=0)\n",
    "df_results[['Hypernym','Hyponym','Frequency']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af0cf8",
   "metadata": {},
   "source": [
    "## üèÜ Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ffee99",
   "metadata": {},
   "source": [
    "#### Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b001c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model\n",
    "nlp_ner = spacy.load(\"./spacy_output/model-best\")\n",
    "\n",
    "# load test lines\n",
    "with open('test_lines.txt', 'r') as f:\n",
    "    test_lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "# read homonym_list.txt with pairs of homonyms\n",
    "homonyms_df = pd.read_csv('hearst_patterns.30.csv')\n",
    "homonyms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c2a40",
   "metadata": {},
   "source": [
    "#### üèÖ Manual Gold dataset\n",
    "Here we are evaluating NER model on the manually created gold dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8381d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!TODO__TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6778b2",
   "metadata": {},
   "source": [
    "#### üåê Word-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc70f19",
   "metadata": {},
   "source": [
    "Here we are evaluating extracted Hypernyms using WordNet. Here is an example how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32036e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_rom = wn.synsets('CD-ROM', pos='n')\n",
    "computer = wn.synsets('computer', pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1523945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for synset in cd_rom:\n",
    "    for synset2 in computer:\n",
    "        print(synset, synset2)\n",
    "        print(\"Score:\", synset.wup_similarity(synset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18f53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_rom[0].shortest_path_distance(computer[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d8f00",
   "metadata": {},
   "source": [
    "Run on our list of hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a41b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordnet_distance(word1, word2):\n",
    "    parent = wn.synsets(word1.replace(' ', '_'))\n",
    "    subclass = wn.synsets(word2.replace(' ', '_'))\n",
    "    scores = [0]\n",
    "    try:\n",
    "        for synset in parent:\n",
    "            for synset2 in subclass:\n",
    "                scores.append(synset.wup_similarity(synset2))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "    return np.round(max(scores), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a83633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate throw homonyms_df\n",
    "results_wordnet = []\n",
    "for index, row in tqdm(homonyms_df.iterrows()):\n",
    "    if row[\"label\"] == -1:\n",
    "        parent = row['word1']\n",
    "        subclass = row['word2']\n",
    "    else:\n",
    "        parent = row['word2']\n",
    "        subclass = row['word1']\n",
    "    res = wordnet_distance(parent, subclass)\n",
    "    results_wordnet.append(res)\n",
    "    print(parent, \"‚¨ÖÔ∏è\", subclass, \": \", res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee313890",
   "metadata": {},
   "source": [
    "Save to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfee981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to dataframe\n",
    "homonyms_df['wordnet_distance'] = results_wordnet "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e286c8",
   "metadata": {},
   "source": [
    "#### üß™ Spacy embeddings\n",
    "What if model already has links between words? Since it's trained on the corpus data, it should be able to find similarity between words.  \n",
    "This is what can be useful while evaluationg our hyponyms list. We could run it and find low-similar elemts for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load large model for comparison\n",
    "nlp = spacy.load(\"./spacy_output/model-best\")\n",
    "\n",
    "word_1 = nlp(\"cloud platform\")\n",
    "word_2 = nlp(\"service provider\")\n",
    "\n",
    "print(word_1, \"<->\", word_2, word_1.similarity(word_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6560176",
   "metadata": {},
   "source": [
    "Run on our list of hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bebb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_score(word1, word2):\n",
    "    word1 = nlp(word1)\n",
    "    word2 = nlp(word2)\n",
    "    return word1.similarity(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate throw homonyms_df\n",
    "results_spacy = []\n",
    "for index, row in tqdm(homonyms_df.iterrows()):\n",
    "    if row[\"label\"] == -1:\n",
    "        parent = row['word1']\n",
    "        subclass = row['word2']\n",
    "    else:\n",
    "        parent = row['word2']\n",
    "        subclass = row['word1']\n",
    "\n",
    "    res = spacy_score(parent, subclass)\n",
    "    results_spacy.append(res)\n",
    "    print(parent, \"‚¨ÖÔ∏è\", subclass, \": \", res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d5f125",
   "metadata": {},
   "source": [
    "Add results to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c635971",
   "metadata": {},
   "outputs": [],
   "source": [
    "homonyms_df['spacy_distance'] = results_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92734f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "homonyms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3edec3",
   "metadata": {},
   "source": [
    "#### üìú Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68dfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwikidata.entity import WikidataItem, WikidataLexeme, WikidataProperty\n",
    "from qwikidata.linked_data_interface import get_entity_dict_from_api\n",
    "from qwikidata.sparql import (get_subclasses_of_item,\n",
    "                              return_sparql_query_results)\n",
    "import wptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4418a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_name = \"computer\"\n",
    "candidate_name = \"iPad\"\n",
    "\n",
    "# get Wikidata item for parent\n",
    "page = wptools.page(parent_name)\n",
    "data = page.get_parse(show=False)\n",
    "q_parent_class = data.data['wikibase']\n",
    "q_parent_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d2cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use convenience function to get subclasses of an item as a list of item ids\n",
    "subclasses_list = get_subclasses_of_item(q_parent_class)\n",
    "len(subclasses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb446b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print some of this classes\n",
    "for subclass in subclasses_list[:5]:\n",
    "    q42_dict = get_entity_dict_from_api(subclass)\n",
    "    print(WikidataItem(q42_dict).get_label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf9175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = wptools.page(candidate_name)\n",
    "data = page.get_parse(show=False)\n",
    "data.data['wikibase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84baa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Is class `{parent_name}` is a subclass of `{candidate_name}`: \", data.data['wikibase'] in subclasses_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a50c67",
   "metadata": {},
   "source": [
    "Run on our list of hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96deb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wikidata_is_subclass(word_1, word_2):\n",
    "    parent_name = word_1\n",
    "    candidate_name = word_2\n",
    "\n",
    "    # get Wikidata item for parent\n",
    "    page = wptools.page(parent_name)\n",
    "    try:\n",
    "        data_parent = page.get_parse(show=False)\n",
    "    except:\n",
    "        print(f\"Could not find Wikidata item for `{parent_name}`\")\n",
    "        return \"‚ö†Ô∏è\"\n",
    "    q_parent_id = data_parent.data['wikibase']\n",
    "\n",
    "    # get Wikidata item for candidate\n",
    "    page = wptools.page(candidate_name)\n",
    "    try:\n",
    "        data_subclass = page.get_parse(show=False)\n",
    "    except:\n",
    "        print(f\"Could not find Wikidata item for `{candidate_name}`\")\n",
    "        return \"‚ö†Ô∏è\"\n",
    "    q_subclass_id = data_subclass.data['wikibase']\n",
    "\n",
    "    # use convenience function to get subclasses of an item as a list of item ids\n",
    "    subclasses_list = get_subclasses_of_item(q_parent_id)\n",
    "\n",
    "    res = q_subclass_id in subclasses_list\n",
    "    if res:\n",
    "        return \"‚úÖ\"\n",
    "    else:\n",
    "        return \"‚ùå\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate throw homonyms_df\n",
    "wikidata_results = []\n",
    "for index, row in tqdm(homonyms_df.iterrows()):\n",
    "    if row[\"label\"] == -1:\n",
    "        parent = row['word1']\n",
    "        subclass = row['word2']\n",
    "    else:\n",
    "        parent = row['word2']\n",
    "        subclass = row['word1']\n",
    "\n",
    "    res = wikidata_is_subclass(parent, subclass)\n",
    "    wikidata_results.append(res)\n",
    "    print(parent, \"‚¨ÖÔ∏è\", subclass, \": \",wikidata_is_subclass(parent, subclass))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9e9fe",
   "metadata": {},
   "source": [
    "Add results to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb34a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "homonyms_df['wikidata_is_subclass'] = wikidata_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "homonyms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d0ab0",
   "metadata": {},
   "source": [
    "#### Process table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d17c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns wordnet_is_subclass, fill with \"‚ö†Ô∏è\" if not 0 or np.nan, otherwise fill with \"‚úÖ\" if wordnet_distance > 0.7, otherwise fill with \"‚ùå\"\n",
    "homonyms_df['wordnet_is_subclass'] = homonyms_df['wordnet_distance'].apply(lambda x: \"‚ö†Ô∏è\" if x == 0 or np.isnan(x) else \"‚úÖ\" if x > 0.7 else \"‚ùå\")\n",
    "\n",
    "# do the same for spacy\n",
    "homonyms_df['spacy_is_subclass'] = homonyms_df['spacy_distance'].apply(lambda x: \"‚ö†Ô∏è\" if x == 0 or np.isnan(x) else \"‚úÖ\" if x > 0.3 else \"‚ùå\")\n",
    "\n",
    "\n",
    "homonyms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40bf4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "homonyms_df[[ \"label\", \"word1\", \"word2\", \"wordnet_is_subclass\", \"spacy_is_subclass\", \"wikidata_is_subclass\"]].to_csv(\"./homonyms_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d553a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "homonyms_df[[\"label\", \"word1\", \"word2\",  \"wordnet_distance\", \"spacy_distance\", \"wordnet_is_subclass\", \"spacy_is_subclass\", \"wikidata_is_subclass\"]].to_csv(\"./homonyms_results_detailed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "699871839e1c28f0580e7fc2e38fa027ae9eff10cc3ccb1dbb0c1a4aca421727"
  },
  "kernelspec": {
   "display_name": "uni-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
