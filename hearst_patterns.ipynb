{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhyper_multi_patterns = [\n",
    "    [ # !(features|properties) Y such as X1 , X2 , . . .\n",
    "        {\"LOWER\": {\"IN\": [\"features\", \"properties\"]}, \"OP\":\"!\"},\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"ORTH\": \",\", \"OP\": '?'},\n",
    "        {\"LOWER\": \"such\"},\n",
    "        {\"LOWER\": \"as\"},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}, \"OP\":'?'},\n",
    "        {\"ENT_TYPE\": \"TECH\"}\n",
    "    ],\n",
    "    [ # Y including X1 , X2 , . . .\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"ORTH\": \",\", \"OP\": '?'},\n",
    "        {\"LOWER\": \"including\"},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}, \"OP\":'?'},\n",
    "        {\"ENT_TYPE\": \"TECH\"} \n",
    "    ]\n",
    "]\n",
    "\n",
    "rhyper_single_patterns = [\n",
    "    [ # (Unlike|like) (most|all|any|other) Y, X\n",
    "        {\"LOWER\": {\"IN\": [\"unlike\", \"like\"]}},\n",
    "        {\"LOWER\": {\"IN\": [\"most\", \"all\", \"any\", \"other\"]}},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}, \"OP\":'?'},\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"ORTH\": \",\"},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}, \"OP\":'?'},\n",
    "        {\"ENT_TYPE\": \"TECH\"}\n",
    "    ]\n",
    "]\n",
    "\n",
    "hyper_single_patterns = [\n",
    "    [ # which is a (example|class|kind|. . . ) of Y\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"LOWER\": \"which\"},\n",
    "        {\"LOWER\": {\"IN\": [\"is\", \"are\"]}},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\"]}},\n",
    "        {\"LOWER\": {\"IN\": [\"example\", \"class\",\"kind\"]}},\n",
    "        {\"LOWER\": \"of\"},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}, \"OP\":'?'},\n",
    "        {\"ENT_TYPE\": \"TECH\"}\n",
    "    ],\n",
    "    [ # X (and|or) (any|some) other Y\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"LOWER\": {\"IN\": [\"and\", \"or\"]}},\n",
    "        {\"LOWER\": {\"IN\": [\"any\", \"some\"]}},\n",
    "        {\"LOWER\": \"other\"},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}, \"OP\":'?'},\n",
    "        {\"ENT_TYPE\": \"TECH\"}\n",
    "    ],\n",
    "    [ # X which is called Y\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"ORTH\": \",\", \"OP\": '?'},\n",
    "        {\"LOWER\": \"which\"},\n",
    "        {\"LOWER\": {\"IN\": [\"is\", \"are\"]}},\n",
    "        {\"LOWER\": {\"IN\": [\"also\", \"sometimes\"]}, \"OP\":\"?\"},\n",
    "        {\"LOWER\": \"called\"},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}, \"OP\":'?'},\n",
    "        {\"ENT_TYPE\": \"TECH\"}\n",
    "    ],\n",
    "    [ # X a special case of Y\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"LOWER\": \"a\"},\n",
    "        {\"LOWER\": \"special\"},\n",
    "        {\"LOWER\": \"case\"},\n",
    "        {\"LOWER\": \"of\"},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}, \"OP\":'?'},\n",
    "        {\"ENT_TYPE\": \"TECH\"}\n",
    "    ],\n",
    "    [ # X is an Y that\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"LOWER\": {\"IN\": [\"is\", \"are\"]}},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}},\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"LOWER\": \"that\"},  \n",
    "    ],\n",
    "    [ # X is a !(member|part|given) Y\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "        {\"LOWER\": {\"IN\": [\"is\", \"are\"]}},\n",
    "        {\"LOWER\": {\"IN\": [\"a\", \"an\",\"the\"]}},\n",
    "        {\"ENT_TYPE\": \"TECH\"},\n",
    "    ],\n",
    "    \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-04-20 23:34:21 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "import sys\n",
    "\n",
    "# this turns on the autotimer, so that every cell has a timing information below\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n",
    "# stop using:\n",
    "# %unload_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.17 s (started: 2022-04-21 00:04:43 +02:00)\n"
     ]
    }
   ],
   "source": [
    "class Hearst_Patterns:\n",
    "    def __init__(self, patterns, model_path=\"spacy/model-new\", text_path=\"G06K.txt\"):\n",
    "\n",
    "        g06k = open(text_path).read().strip()\n",
    "        self.patent_lines = g06k.split('\\n')\n",
    "        \n",
    "        self.nlp = spacy.load(model_path)\n",
    "        self.en_nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "        self.nlp.add_pipe(\"merge_entities\")\n",
    "        self.en_nlp.add_pipe('merge_noun_chunks')\n",
    "\n",
    "        self.matcher = Matcher(self.nlp.vocab)\n",
    "        self.continue_words = [',','and','or',';','also']\n",
    "\n",
    "        for name, pattern in patterns:\n",
    "            self.matcher.add(name, pattern)\n",
    "\n",
    "    def extract_patterns(self, size=10, save_folder=\".\", start=0):\n",
    "        extraced_patterns = []\n",
    "        line = start\n",
    "        count = 0\n",
    "        print(f'{count} pattern extracted...', end='\\r')\n",
    "        sys.stdout.flush()\n",
    "        try:\n",
    "            while count<size:\n",
    "                while True:\n",
    "                    patterns = hp.get_matches(self.patent_lines[line])\n",
    "                    line += 1\n",
    "                    if patterns:\n",
    "                        extraced_patterns += patterns\n",
    "                        break\n",
    "                    print(f'{count} patterns extracted...{line}', end='\\r')\n",
    "                    sys.stdout.flush()\n",
    "                    \n",
    "                count = len(extraced_patterns)\n",
    "                print(f'{count} patterns extracted...{line}', end='\\r')\n",
    "                sys.stdout.flush()\n",
    "        except:\n",
    "            print(\"An error has occurred\")\n",
    "\n",
    "        print(f'({count}) patterns extracted from lines ({start}-{line}))')\n",
    "        save_file = f\"{save_folder}/hearst_patterns.{len(extraced_patterns)}.csv\"\n",
    "        print(f'Patterns saved to {save_file}')\n",
    "        df = pd.DataFrame(extraced_patterns, columns =['word1', 'word2', 'relation', 'label', 'text'])\n",
    "        df.to_csv(save_file)\n",
    "\n",
    "    def get_matches(self, text):\n",
    "        label = {\n",
    "            'rhyper':-1,\n",
    "            'hyper':1,\n",
    "        }\n",
    "        doc = self.nlp('. '+text)\n",
    "        matches = self.matcher(doc)\n",
    "        relations = []\n",
    "        for match_id, start, end in matches:\n",
    "            ent_indices = [i for i in range(start,end) if doc[i].text in [ent.text for ent in doc[start:end].ents]]\n",
    "            if not ent_indices:\n",
    "                return []\n",
    "\n",
    "            span = doc[min(ent_indices):max(ent_indices)+1]\n",
    "\n",
    "            match_info = self.nlp.vocab.strings[match_id]  # Get string representation\n",
    "            match_name = match_info.split('-')[0]\n",
    "            match_type = match_info.split('-')[1]\n",
    "\n",
    "            np_0 = span[0]\n",
    "            np_1 = span[-1]\n",
    "            right_terms = [np_1.text]\n",
    "            if match_type==\"multi\":\n",
    "                doc_parser = self.en_nlp(doc[end:].text)\n",
    "                for d in doc_parser:\n",
    "                    matching_ents = [ent.text for ent in doc.ents if ent.text in d.text]\n",
    "                    if matching_ents:\n",
    "                        right_terms.append(matching_ents[0])\n",
    "                    elif d.text not in self.continue_words:\n",
    "                        break\n",
    "\n",
    "            for term in right_terms:\n",
    "                relations.append((np_0.text, term, match_name, label[match_name], text))\n",
    "\n",
    "        relations = set(relations)\n",
    "        return list(relations)\n",
    "\n",
    "\n",
    "patterns = [ (\"rhyper-multi\", rhyper_multi_patterns), (\"hyper-single\", hyper_single_patterns), (\"rhyper-single\", rhyper_single_patterns) ]\n",
    "hp = Hearst_Patterns(patterns, model_path=\"../spacy/model-new\", text_path=\"../G06K.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-04-21 02:13:14 +02:00)\n"
     ]
    }
   ],
   "source": [
    "hp.extract_patterns(size=50, start=5896)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "last line processed 26331"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-04-21 02:15:24 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hearst_patterns/formatted_hearst_patterns.155.csv\")\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-04-21 02:16:25 +02:00)\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"hearst_patterns/formatted_hearst_patterns.155.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd2970738afc46eb75cb987fc9351c35334a088948a4b8985da4d246077f4773"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
